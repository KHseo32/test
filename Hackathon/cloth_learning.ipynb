{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def preprocess_images(images, target_size=(100, 100)):\n",
    "    preprocessed_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, target_size)\n",
    "        normalized_img = resized_img / 255.0  # Normalize pixel values\n",
    "        preprocessed_images.append(normalized_img.astype(np.uint8))  # Convert to CV_8UC3\n",
    "    return np.array(preprocessed_images)\n",
    "\n",
    "# Define folder paths\n",
    "folder_paths = [\n",
    "    './raffaello',\n",
    "    './COAP',\n",
    "    './COAP/bag',\n",
    "    './COAP/dress',\n",
    "    './COAP/outers',\n",
    "    './COAP/pants',\n",
    "    './COAP/shoes',\n",
    "    './COAP/top',\n",
    "    './GABABA/outers',\n",
    "    './GABABA/pants',\n",
    "    './GABABA/tops',\n",
    "    './ZARA_men/bag',\n",
    "    './ZARA_men/outer',\n",
    "    './ZARA_men/pants',\n",
    "    './ZARA_men/shoes',\n",
    "    './ZARA_men/top'\n",
    "]\n",
    "\n",
    "# Load all images from folders\n",
    "all_images = []\n",
    "for folder_path in folder_paths:\n",
    "    all_images.extend(load_images_from_folder(folder_path))\n",
    "\n",
    "# Preprocess all images\n",
    "processed_images = preprocess_images(all_images)\n",
    "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
    "\n",
    "# Initialize MiniBatchKMeans object\n",
    "num_clusters = 5  # Specify number of clusters\n",
    "kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans to data\n",
    "kmeans.fit(flattened_images)\n",
    "\n",
    "# Create directories for each cluster\n",
    "output_dir = \"./clustered_data\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Save images to cluster folders\n",
    "for i in range(num_clusters):\n",
    "    cluster_dir = os.path.join(output_dir, f\"cluster_{i}\")\n",
    "    if not os.path.exists(cluster_dir):\n",
    "        os.makedirs(cluster_dir)\n",
    "    cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "    for idx in cluster_indices:\n",
    "        img = all_images[idx]\n",
    "        filename = f\"image_{idx}.jpg\"\n",
    "        cv2.imwrite(os.path.join(cluster_dir, filename), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "def load_images_from_folders(folders):\n",
    "    images = []\n",
    "    for folder in folders:\n",
    "        for filename in os.listdir(folder):\n",
    "            img = cv2.imread(os.path.join(folder, filename))\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "    return images\n",
    "\n",
    "def preprocess_images(images, target_size=(100, 100)):\n",
    "    preprocessed_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, target_size)\n",
    "        normalized_img = resized_img / 255.0  # Normalize pixel values\n",
    "        preprocessed_images.append(normalized_img.astype(np.uint8))  # Convert to CV_8UC3\n",
    "    return np.array(preprocessed_images)\n",
    "\n",
    "# Define folder paths\n",
    "folder_paths = [\n",
    "    './raffaello',\n",
    "    './COAP',\n",
    "    './COAP/bag',\n",
    "    './COAP/dress',\n",
    "    './COAP/outers',\n",
    "    './COAP/pants',\n",
    "    './COAP/shoes',\n",
    "    './COAP/top',\n",
    "    './GABABA/outers',\n",
    "    './GABABA/pants',\n",
    "    './GABABA/tops',\n",
    "    './ZARA_men/bag',\n",
    "    './ZARA_men/outer',\n",
    "    './ZARA_men/pants',\n",
    "    './ZARA_men/shoes',\n",
    "    './ZARA_men/top'\n",
    "]\n",
    "\n",
    "output_folder = \"./clustered_data_2\"\n",
    "num_clusters = 10  # Number of clusters\n",
    "\n",
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load images from folders\n",
    "all_images = load_images_from_folders(folder_paths)\n",
    "\n",
    "# Preprocess all images\n",
    "processed_images = preprocess_images(all_images)\n",
    "flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
    "\n",
    "# Initialize MiniBatchKMeans object with 10 clusters\n",
    "kmeans = MiniBatchKMeans(n_clusters=num_clusters, random_state=42)\n",
    "\n",
    "# Fit KMeans to data\n",
    "kmeans.fit(flattened_images)\n",
    "\n",
    "# Save clustered data into new folders in the output folder\n",
    "for i in range(num_clusters):\n",
    "    cluster_folder = os.path.join(output_folder, f\"cluster_{i}\")\n",
    "    if not os.path.exists(cluster_folder):\n",
    "        os.makedirs(cluster_folder)\n",
    "    cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
    "    for idx in cluster_indices:\n",
    "        img = all_images[idx]\n",
    "        filename = f\"image_{idx}.jpg\"\n",
    "        cv2.imwrite(os.path.join(cluster_folder, filename), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_0 re_cluster\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder, filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "def preprocess_images(images, target_size=(100, 100)):\n",
    "    preprocessed_images = []\n",
    "    for img in images:\n",
    "        resized_img = cv2.resize(img, target_size)\n",
    "        normalized_img = resized_img / 255.0  # Normalize pixel values\n",
    "        preprocessed_images.append(normalized_img.astype(np.uint8))  # Convert to CV_8UC3\n",
    "    return np.array(preprocessed_images)\n",
    "\n",
    "def run_machine_learning(folder_path, num_groups, output_folder):\n",
    "    # Load images from the cluster folder\n",
    "    images = load_images_from_folder(folder_path)\n",
    "    # Preprocess images\n",
    "    processed_images = preprocess_images(images)\n",
    "    flattened_images = processed_images.reshape(processed_images.shape[0], -1)\n",
    "    # Initialize MiniBatchKMeans object with specified number of groups\n",
    "    kmeans = MiniBatchKMeans(n_clusters=num_groups, random_state=42)\n",
    "    # Fit KMeans to data\n",
    "    kmeans.fit(flattened_images)\n",
    "    # Save clustered data into new folders in the output folder\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    for i in range(num_groups):\n",
    "        group_folder = os.path.join(output_folder, f\"group_{i}\")\n",
    "        if not os.path.exists(group_folder):\n",
    "            os.makedirs(group_folder)\n",
    "        group_indices = np.where(kmeans.labels_ == i)[0]\n",
    "        for idx in group_indices:\n",
    "            img = images[idx]\n",
    "            filename = f\"image_{idx}.jpg\"\n",
    "            cv2.imwrite(os.path.join(group_folder, filename), img)\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_0\"\n",
    "output_folder = \"./clustered_data_3/CL_0\"\n",
    "num_groups = 4\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_2 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_2\"\n",
    "output_folder = \"./clustered_data_3/CL_2\"\n",
    "num_groups = 5\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_3 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_3\"\n",
    "output_folder = \"./clustered_data_3/CL_3\"\n",
    "num_groups = 3\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_5 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_5\"\n",
    "output_folder = \"./clustered_data_3/CL_5\"\n",
    "num_groups = 2\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_6 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_6\"\n",
    "output_folder = \"./clustered_data_3/CL_6\"\n",
    "num_groups = 3\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_8 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_8\"\n",
    "output_folder = \"./clustered_data_3/CL_8\"\n",
    "num_groups = 3\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_9 re_cluster\n",
    "\n",
    "# Define folder paths and number of groups\n",
    "input_folder = \"./clustered_data_2/cluster_9\"\n",
    "output_folder = \"./clustered_data_3/CL_9\"\n",
    "num_groups = 2\n",
    "\n",
    "# Run machine learning code\n",
    "run_machine_learning(input_folder, num_groups, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
